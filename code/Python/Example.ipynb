{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm, trange  # For displaying progress bars\n",
    "from copy import deepcopy\n",
    "import syncopy as spy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Allen SDK for accessing the EcephysProjectCache (electrophysiology data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the path for the JSON manifest file (required by Allen SDK for file management)\n",
    "# The data in the JSON file determines where downloaded data will be stored. See Allen SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_path = os.path.join(os.path.curdir, 'manifest.json')\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "sessions = cache.get_session_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data parameters for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimType = \"flashes\"  # 'flashes' 'drifting_gratings'  'gabors'\n",
    "bipolar = 1  # 1:bipolar derivation   0:unipolar\n",
    "sample_freq = 1250\n",
    "sample_freq_rawdata = 30_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a session to analyze based on its index in the session table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesnum = 7\n",
    "ses_id = sessions.index.values[sesnum]\n",
    "session = cache.get_session_data(ses_id)\n",
    "probes = cache.get_probes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve presentation times for the specified stimulus type (Cut trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(session.stimulus_presentations.stimulus_name))\n",
    "presentation_table = session.stimulus_presentations[\n",
    "    session.stimulus_presentations.stimulus_name == stimType]\n",
    "presentation_times = presentation_table.start_time.values\n",
    "presentation_ids = presentation_table.index.values\n",
    "win = np.arange(-.25, .25, 1 / sample_freq) # Define time window around each stimulus presentation\n",
    "stim_lbl = session.get_stimulus_table([stimType])['color'] # Get stimulus labels\n",
    "prob_range = session.probes.index.values # Define range of probes in the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Allen data and save the spikes in Syncopy file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spy_spikes():\n",
    "    \"\"\"\n",
    "    Function to extract spike data from Allen SDK, process it, and save it in Syncopy file format.\n",
    "    \"\"\"\n",
    "    print(\"Creating Syncopy spike data file...\")\n",
    "\n",
    "    offset = -0.25 * sample_freq  # Offset in samples for each trial\n",
    "\n",
    "    # first assemble units of interest based on firing rate \n",
    "    units_oi = []\n",
    "    for prob_ind in tqdm(prob_range):\n",
    "        units_oi += list(session.units[(session.units.probe_id == prob_ind) &\n",
    "                                       (session.units.firing_rate > 10) &\n",
    "                                       (session.units.nn_hit_rate > 0.95)].index)\n",
    "\n",
    "    # Loop over trials for each stimulus presentation\n",
    "    spy_spikes = []\n",
    "    trldef_rows = []\n",
    "    active_units = []\n",
    "    for stim_time in tqdm(presentation_times):\n",
    "\n",
    "        start = stim_time - 0.25\n",
    "        stop = stim_time + 0.25\n",
    "\n",
    "        # 2d array with columns: samples, channel, unit.\n",
    "        # Channel is not given/interesting for spike data and has to be 0.\n",
    "        channel_id = 0\n",
    "\n",
    "        spy_trl = []\n",
    "\n",
    "        for unit_idx, unit_id in enumerate(units_oi):\n",
    "\n",
    "            unit_spike_times = session.spike_times[unit_id]\n",
    "            # index time window\n",
    "            bool_index = (unit_spike_times > start) & (unit_spike_times < stop)\n",
    "            # relevant spikes in samples\n",
    "            unit_spike_samples = (\n",
    "                unit_spike_times[bool_index] + start) * sample_freq\n",
    "\n",
    "            # Skip units without spikes in this window\n",
    "            if unit_spike_samples.size == 0:\n",
    "                continue\n",
    "\n",
    "            active_units.append(unit_id)\n",
    "\n",
    "            spy_trl.append(np.array([(sp_sample, channel_id, unit_idx) for\n",
    "                                     sp_sample in unit_spike_samples], dtype=np.int64))\n",
    "\n",
    "        spy_trl = np.vstack(spy_trl)\n",
    "        spy_trl = spy_trl[spy_trl[:, 0].argsort()] # Sort spike samples by time\n",
    "        spy_spikes.append(spy_trl)\n",
    "\n",
    "        trldef_rows.append([spy_trl[0, 0], spy_trl[-1, 0], offset])\n",
    "\n",
    "    trldef = np.vstack(trldef_rows)\n",
    "    spy_spikes = spy.SpikeData(data=spy_spikes, samplerate=sample_freq)\n",
    "\n",
    "    spy_spikes.trialdefinition = trldef\n",
    "    # unit labels have to be strings\n",
    "    spy_spikes.unit = list(map(str, set(active_units)))\n",
    "\n",
    "    # Add custom metadata: raw sampling rate.\n",
    "    spy_spikes.info['fsample_raw'] = sample_freq_rawdata\n",
    "\n",
    "    # Finally save to disc.\n",
    "    spy_spikes.save(os.path.join(\n",
    "        os.path.curdir, 'allen_spike'), overwrite=True)\n",
    "    # return Spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Allen data and save the LFP data in Syncopy file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spy_lfp():\n",
    "    \"\"\"\n",
    "    Function to extract LFP data, process it for each stimulus presentation, and save it in Syncopy file format.\n",
    "    \"\"\"\n",
    "    print(\"Creating Syncopy LFP data file...\")\n",
    "\n",
    "    loc = []            # Channel locations\n",
    "    ds = []             # LFP data for each trial\n",
    "    twin = []           # Time windows for each trial\n",
    "    lfps = []\n",
    "    lfp_channel_id = [] # Channel IDs for bipolar or unipolar data\n",
    "\n",
    "    # Attempt to retrieve LFP data for each probe\n",
    "    for prob_ind in tqdm(prob_range):\n",
    "        try:\n",
    "            lfps.append(session.get_lfp(prob_ind))\n",
    "        except:\n",
    "            print(f\"No LFP in this electrode:{prob_range}\")\n",
    "            continue\n",
    "\n",
    "    for tr in trange(len(presentation_times)):\n",
    "        lfp_buf = [] # Buffer to store LFP data for the current trial\n",
    "\n",
    "        # Append LFP of all channels\n",
    "        for _, lfp in enumerate(lfps):\n",
    "            ch_range = lfp.channel.values\n",
    "            for z in range(len(ch_range)):\n",
    "                channel_ids = ch_range[z]\n",
    "                try:\n",
    "                    # Retrieve bipolar or unipolar LFP data depending on the parameter set\n",
    "                    if bipolar == 1:\n",
    "                        lfp_tmp = (lfp.sel(time=(presentation_times[tr]+win), method='nearest', channel=ch_range[z]))-(\n",
    "                            lfp.sel(time=(presentation_times[tr]+win), method='nearest', channel=ch_range[z+1]))\n",
    "                        loc_tmp = (\n",
    "                            session.channels.ecephys_structure_acronym[channel_ids])\n",
    "                    elif bipolar == 0:\n",
    "                        lfp_tmp = (lfp.sel(\n",
    "                            time=(presentation_times[tr]+win), method='nearest', channel=channel_ids))\n",
    "                        loc_tmp = (\n",
    "                            session.channels.ecephys_structure_acronym[channel_ids])\n",
    "\n",
    "                    if tr == 0:\n",
    "                        loc.append(loc_tmp)\n",
    "                        if bipolar == 1:\n",
    "                            lfp_channel_id.append([ch_range[z], ch_range[z+1]])\n",
    "                        elif bipolar == 0:\n",
    "                            lfp_channel_id.append(channel_ids)\n",
    "                    lfp_buf.append(lfp_tmp)\n",
    "                    lfp_buf[-1] = np.nan_to_num(\n",
    "                        lfp_buf[-1].values.reshape(1, -1))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        ds.append(np.concatenate(lfp_buf, axis=0).T)\n",
    "        twin.append(deepcopy(win))\n",
    "\n",
    "    # Put data into Syncopy objects.\n",
    "    lfp = spy.AnalogData(data=ds, samplerate=sample_freq)\n",
    "    lfp.info['Label'] = loc\n",
    "    lfp.info['stim_lbl'] = list(stim_lbl)\n",
    "    lfp.info['Twin'] = [arr.tolist() for arr in twin]\n",
    "\n",
    "    # Finally save to disc.\n",
    "    lfp.save(os.path.join(os.path.curdir, 'allen_lfp'), overwrite=True)\n",
    "    # return LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Allen data and save data in Fieldtrip-compatible (MATLAB) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ft():\n",
    "    \"\"\"\n",
    "    Function to extract both spike and LFP data, process it, and save it in Fieldtrip-compatible format.\n",
    "    \"\"\"\n",
    "    print(\"Creating Fieldtrip data file...\")\n",
    "\n",
    "    spikes = []\n",
    "    loc = []\n",
    "    locspk = []\n",
    "    ds = []\n",
    "    ds_spk = []\n",
    "    twin = []\n",
    "    lfps = []\n",
    "    spk_channel_id = []\n",
    "    lfp_channel_id = []\n",
    "\n",
    "    fieldtrip = {\"Label\": [],  # cell(1*chNum)\n",
    "                 \"Labelspk\": [],\n",
    "                 \"chIDlfp\": [],\n",
    "                 \"chIDspk\": [],\n",
    "                 \"trialinfo\": {},  # double(trialNum*info)\n",
    "                 \"trial\": [],          # cell(1*trialNum) >> (chNum*sample)\n",
    "                 \"trial_spike\": [],\n",
    "                 \"time\": [],           # cell(1*trialNum) >> (1*sample)\n",
    "                 \"fsample\": sample_freq,        # sampling rate  1250\n",
    "                 \"fsample_raw\": sample_freq_rawdata,\n",
    "                 # 1*1 structure (other infor) >> not necessary\n",
    "                 \"cfg\": []\n",
    "                 }\n",
    "\n",
    "    # Append spikes of all channels\n",
    "    for prob_ind in tqdm(prob_range):\n",
    "        try:\n",
    "            lfps.append(session.get_lfp(prob_ind))\n",
    "        except:\n",
    "            continue\n",
    "        units_of_interest = (session.units[(session.units.probe_id == prob_ind) &\n",
    "                                           (session.units.firing_rate > 10) &\n",
    "                                           (session.units.nn_hit_rate > 0.95)])\n",
    "        for i in range(len(units_of_interest)):\n",
    "            unit_id = units_of_interest.index.values[i]\n",
    "            channel_index = units_of_interest .loc[unit_id].probe_channel_number\n",
    "            spk_channel_id.append(session.channels[(session.channels.probe_channel_number == channel_index) &\n",
    "                                                   (session.channels.probe_id == prob_ind)].index.values[0])\n",
    "            spikes.append(session.spike_times[unit_id])\n",
    "\n",
    "    for tr in trange(len(presentation_times)):\n",
    "        lfp_buf = []\n",
    "        spk_buf = []\n",
    "        for unitNum in range(len(spikes)):\n",
    "            tmp = np.zeros(len(win))\n",
    "            sp = (spikes[unitNum][(spikes[unitNum] > presentation_times[tr]+win[0]) &\n",
    "                                  (spikes[unitNum] < presentation_times[tr]+win[-1])])-(presentation_times[tr]+win[0])\n",
    "            for i in sp:\n",
    "                tmp[int(i*fieldtrip['fsample'])] = 1\n",
    "            spk_buf.append(tmp)\n",
    "            if tr == 0:\n",
    "                locspk.append(\n",
    "                    session.channels.ecephys_structure_acronym[spk_channel_id[unitNum]])\n",
    "\n",
    "        # Append LFP of all channels\n",
    "        for _, lfp in enumerate(lfps):\n",
    "            ch_range = lfp.channel.values\n",
    "            for z in range(len(ch_range)):\n",
    "                channel_ids = ch_range[z]\n",
    "                try:\n",
    "                    if bipolar == 1:\n",
    "                        lfp_tmp = (lfp.sel(time=(presentation_times[tr]+win), method='nearest', channel=ch_range[z]))-(\n",
    "                            lfp.sel(time=(presentation_times[tr]+win), method='nearest', channel=ch_range[z+1]))\n",
    "                        loc_tmp = (\n",
    "                            session.channels.ecephys_structure_acronym[channel_ids])\n",
    "                    elif bipolar == 0:\n",
    "                        lfp_tmp = (lfp.sel(\n",
    "                            time=(presentation_times[tr]+win), method='nearest', channel=channel_ids))\n",
    "                        loc_tmp = (\n",
    "                            session.channels.ecephys_structure_acronym[channel_ids])\n",
    "                    if tr == 0:\n",
    "                        loc.append(loc_tmp)\n",
    "                        if bipolar == 1:\n",
    "                            lfp_channel_id.append([ch_range[z], ch_range[z+1]])\n",
    "                        elif bipolar == 0:\n",
    "                            lfp_channel_id.append(channel_ids)\n",
    "                    lfp_buf.append(lfp_tmp)\n",
    "                    lfp_buf[-1] = np.nan_to_num(\n",
    "                        lfp_buf[-1].values.reshape(1, -1))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        ds.append(np.concatenate(lfp_buf, axis=0).T)\n",
    "        print(ds[-1].shape)\n",
    "        twin.append(deepcopy(win))\n",
    "        ds_spk.append(list(map(list, zip(*spk_buf))))\n",
    "    \n",
    "    # Save the data in Fieldtrip-compatible format\n",
    "    fieldtrip[\"trial\"] = ds\n",
    "    fieldtrip[\"spike\"] = ds_spk\n",
    "    fieldtrip[\"Label\"] = loc\n",
    "    fieldtrip[\"Labelspk\"] = locspk\n",
    "    fieldtrip[\"time\"] = twin\n",
    "    fieldtrip[\"trialinfo\"] = {'stim_lbl': stim_lbl,\n",
    "                              'chIDlfp': lfp_channel_id,\n",
    "                              'chIDspk': spk_channel_id\n",
    "                              }\n",
    "    fieldtrip2 = deepcopy(fieldtrip)\n",
    "    fieldtrip2[\"trialinfo\"] = []\n",
    "    fieldtrip2[\"stim_lbl\"] = list(stim_lbl)\n",
    "\n",
    "    savemat(os.path.join(os.path.curdir, 'allen_FT.mat'), fieldtrip2)\n",
    "\n",
    "# Execute the functions if running as a script\n",
    "if __name__ == \"__main__\":\n",
    "    read_spy_spikes()\n",
    "    read_spy_lfp()\n",
    "    read_ft()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-lock raster plot and peri-stimulus time histogram of spiking activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syncopy as spy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set parameters and load spike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "saveFig = 1             # 0:not savefigs  1: save figs\n",
    "spikeData = spy.load('allen_spike.spy')\n",
    "data_spk = spikeData.trials\n",
    "samplerate = 1250\n",
    "offset = -0.25 * samplerate  # Offset in samples for aligning samples to stimulus onset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitID = '951009344'\n",
    "unitname = 'unit30'\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "spikeData.singlepanelplot(unit=unitID)\n",
    "\n",
    "if saveFig == 1:\n",
    "    plt.savefig(\"Raster.png\")\n",
    "    plt.savefig(\"Raster.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = spy.StructDict()\n",
    "cfg.latency = \"minperiod\"  # to avoid NaNs\n",
    "cfg.output = \"rate\"\n",
    "cfg.binsize = 0.01  # in seconds\n",
    "spike_rate = spy.spike_psth(spikeData, cfg)\n",
    "\n",
    "# Remove channel0 from channel names.\n",
    "chan_names = [old_name.split('_')[1] for old_name in spike_rate.channel]\n",
    "spike_rate.channel = chan_names\n",
    "\n",
    "# Compute the mean.\n",
    "rate_trl_mean = spy.mean(spike_rate, dim='trials')\n",
    "\n",
    "# Plot.\n",
    "fig, ax = rate_trl_mean.singlepanelplot(channel=unitname)\n",
    "ax.set_ylabel('spike rate (1/s)')\n",
    "fig.tight_layout()\n",
    "\n",
    "if saveFig == 1:\n",
    "    plt.savefig(\"PSTH.png\")\n",
    "    plt.savefig(\"PSTH.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power spectrum of LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import syncopy as spy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set parameters and load LFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "saveFig = 1             # 0:not savefigs  1: save figs\n",
    "freq_range = [15, 90]   # frequency range\n",
    "fs = 1250               # sampling rate\n",
    "areas = {\n",
    "    \"V1L\": ['VISl'],\n",
    "    \"V1RL\": ['VISrl'],\n",
    "    \"Thal-MG\": ['MGv'],\n",
    "    \"Thal-LP\": ['LP']\n",
    "}\n",
    "\n",
    "# Load data\n",
    "lfpdata = spy.load('allen_lfp.spy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select stimulus and baseline epochs for analysis\n",
    "L = len(lfpdata.time[0])\n",
    "base_time = np.arange(0, np.ceil(L/2)-1, 1)\n",
    "stim_time = np.arange(np.floor(L/2), L-1, 1)\n",
    "TW_base = [lfpdata.time[0][int(base_time[0])],\n",
    "           lfpdata.time[0][int(base_time[-1])]]\n",
    "TW_stim = [lfpdata.time[0][int(stim_time[0])],\n",
    "           lfpdata.time[0][int(stim_time[-1])]]\n",
    "data_base = lfpdata.selectdata(latency=TW_base)\n",
    "data_stim = lfpdata.selectdata(latency=TW_stim)\n",
    "\n",
    "# Initialize configuration settings for Syncopy power analysis\n",
    "cfg = []\n",
    "cfg = spy.get_defaults(spy.freqanalysis)\n",
    "cfg.method = 'mtmfft'\n",
    "cfg.output = 'pow'\n",
    "cfg.pad = 1\n",
    "cfg.taper = 'hann'\n",
    "cfg.nTaper = 1\n",
    "cfg.keeptrials = True\n",
    "cfg.foilim = freq_range\n",
    "\n",
    "# Baseline correction\n",
    "psd_stim = spy.freqanalysis(cfg, data_stim)\n",
    "psd_base = spy.freqanalysis(cfg, data_base)\n",
    "psd = []\n",
    "psd2 = []\n",
    "psd = psd_stim\n",
    "powbs = (np.mean(psd_base.data, axis=0))\n",
    "psd.data = psd_stim.data/powbs\n",
    "selectch = np.arange(0, len(psd.channel), 1)\n",
    "pow = psd.data\n",
    "\n",
    "# Outlier detection\n",
    "outl = np.nanmean(np.nanmean(pow, axis=2), axis=0) > (np.nanmean(\n",
    "    np.reshape(pow, (1, -1)), axis=1)+3*np.std(np.reshape(pow, (1, -1)), axis=1))\n",
    "indices = np.where(outl)[0]\n",
    "selch = np.delete(selectch, indices)\n",
    "spy.selectdata(psd, channel=list(lfpdata.channel[selch]))\n",
    "\n",
    "cfg = spy.StructDict()\n",
    "psd2 = spy.selectdata(cfg, psd)\n",
    "\n",
    "# Grand power\n",
    "channelLBL = lfpdata.info['Label']\n",
    "GrandPSD = spy.mean(psd2, dim='trials')\n",
    "iter = 1\n",
    "Pow = []\n",
    "\n",
    "# for area_iter in areas.keys():\n",
    "area_iter = list(areas.keys())[0]\n",
    "area = []\n",
    "y = []\n",
    "y_tmp = []\n",
    "indexes = []\n",
    "for i in areas[f\"{area_iter}\"]:\n",
    "    indexes.append([index for index in range(\n",
    "        len(channelLBL)) if channelLBL[index] == i])\n",
    "chindx = list(map(int, np.concatenate(indexes)))\n",
    "\n",
    "y_tmp = spy.selectdata(GrandPSD, channel=chindx)\n",
    "y = spy.mean(y_tmp, dim='channel')\n",
    "fig, ax = y.singlepanelplot(logscale=False)\n",
    "ax.set_title(f\"ch= {area_iter}\")\n",
    "ax.set_xlabel('Frequency(Hz)')\n",
    "ax.set_ylabel('Syncopy power')\n",
    "ax.set_xlim([1, 90])\n",
    "Pow.append(np.squeeze(y.data))\n",
    "iter = iter+1\n",
    "\n",
    "if saveFig == 1:\n",
    "    plt.savefig(f'power{area_iter}.png')\n",
    "    plt.savefig(f'power{area_iter}.pdf')\n",
    "\n",
    "pickle.dump(Pow, open(f\"SavedData/PyPow.plk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import syncopy as spy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set parameters and load LFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "cohppcGC = 1  # 1: coh  2:ppc 3:GC\n",
    "saveFig = 1             # 0:not savefigs  1: save figs\n",
    "freq_range = [1, 100]   # frequency range\n",
    "fs = 1250               # sampling rate\n",
    "areas = {\n",
    "    \"V1L\": ['VISl'],\n",
    "    \"V1RL\": ['VISrl'],\n",
    "    \"Thal-MG\": ['MGv'],\n",
    "    \"Thal-LP\": ['LP']\n",
    "}\n",
    "\n",
    "# Load data\n",
    "lfpdata = spy.load('allen_lfp.spy')\n",
    "channelLBL = lfpdata.info['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  connectivity estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(lfpdata.time[0]) # Length of the time series for LFP data\n",
    "stim_time = np.arange(np.floor(L/2), L-1, 1) # Define stimulus time range\n",
    "TW_stim = [lfpdata.time[0][int(stim_time[0])],\n",
    "           lfpdata.time[0][int(stim_time[-1])]] # Define time window for analysis\n",
    "data_stim_all = lfpdata.selectdata(latency=TW_stim)  # Select data within the specified time window for analysis\n",
    "\n",
    "\n",
    "# Initialize configuration settings for Syncopy connectivity analysis\n",
    "cfg = []\n",
    "cfg = spy.StructDict()\n",
    "if cohppcGC == 1:\n",
    "    cfg.method = 'coh' # Coherence method\n",
    "elif cohppcGC == 2:\n",
    "    cfg.method = 'ppc' # Pairwise phase consistency\n",
    "elif cohppcGC == 3:\n",
    "    cfg.method = 'granger'  # Granger causality\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "cfg.pad = 1  # 'maxperlen'     # Padding applied to time series\n",
    "# Optional configuration settings for spectral analysis (tapering and smoothing)\n",
    "# cfg.taper = 'None' #'hann'  # 'dpss' 'hann'\n",
    "# cfg.nTaper = 1\n",
    "# cfg.tapsmofrq = 3\n",
    "\n",
    "# Loop over defined brain areas and their channels to compute connectivity\n",
    "area_num = list(areas.keys())\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "iter = 0\n",
    "\n",
    "# Iterate over pairs of areas (sender and receiver) to calculate connectivity metrics\n",
    "for sender in range(0, 1):  # range(len(area_num)):  # -1    # Iterate over each sender area\n",
    "    for receiver in range(1, 2):  # range(len(area_num)):  # sender+1,    # Iterate over each receiver area\n",
    "        iter = iter+1\n",
    "        if receiver > sender:\n",
    "            # For each sender and receiver pair, find and analyze relevant channels\n",
    "            for sender_ch in areas[area_num[sender]]:\n",
    "                for receiver_ch in areas[area_num[receiver]]:\n",
    "                    Con12 = []  # Storage for sender-to-receiver connectivity\n",
    "                    Con21 = []  # Storage for receiver-to-sender connectivity\n",
    "                    ch1 = []  # Lists to hold the channel indices\n",
    "                    ch2 = []\n",
    "                    ppc_val = []  # PPC and feedback PPC values\n",
    "                    ppc_val_FB = []\n",
    "                    \n",
    "                    # Find indices for the channels based on the labels\n",
    "                    for index, item in enumerate(channelLBL):\n",
    "                        if item == sender_ch:\n",
    "                            ch1.append(index)\n",
    "                        if item == receiver_ch:\n",
    "                            ch2.append(index)\n",
    "                    # ch1 = np.nonzero(channelLBL == sender_ch)[0]\n",
    "                    # ch2 = np.nonzero(channelLBL == receiver_ch)[0]\n",
    "\n",
    "                    # Iterate over channel combinations for sender and receiver\n",
    "                    for c1 in ch1:\n",
    "                        for c2 in ch2:\n",
    "                            print(c1)\n",
    "                            chsV1V2 = np.concatenate((c1, c2), axis=None)\n",
    "                            data_stim_subGroup = spy.selectdata(\n",
    "                                data_stim_all, channel=chsV1V2)\n",
    "                            \n",
    "                            # Perform connectivity analysis based on method specified in cfg\n",
    "                            ppc = spy.connectivityanalysis(\n",
    "                                data_stim_subGroup, cfg)\n",
    "                            fr = np.where((ppc.freq >= 15) &\n",
    "                                          (ppc.freq <= 90))[0]\n",
    "                            fr = fr+1\n",
    "\n",
    "                            # Identify sender and receiver indices within channel pair\n",
    "                            c11 = []\n",
    "                            c22 = []\n",
    "                            for index, item in enumerate(chsV1V2):\n",
    "                                if channelLBL[item] == sender_ch:\n",
    "                                    c11.append(index)\n",
    "                                if channelLBL[item] == receiver_ch:\n",
    "                                    c22.append(index)\n",
    "                            # ppc_val = spy.selectdata(ppc, frequency=[min(fr), max(fr)], channel_i=c11, channel_j=c22)\n",
    "                            tmp1 = ppc.data[0]\n",
    "                            tmp2 = tmp1[fr, c11, c22]\n",
    "                            Con12.append(tmp2)\n",
    "                            # # Con12.append(np.squeeze(ppc_val.data))\n",
    "\n",
    "                            # If method is Granger causality, also calculate feedback direction\n",
    "                            if cohppcGC == 3:\n",
    "                                ppc_val_FB = spy.selectdata(\n",
    "                                    ppc, frequency=[min(fr), max(fr)], channel_i=c22, channel_j=c11)\n",
    "                                # # Con21.append(np.squeeze(ppc_val_FB.data))\n",
    "                                tmp1 = []\n",
    "                                tmp2 = []\n",
    "                                tmp1 = ppc.data[0]\n",
    "                                tmp2 = tmp1[fr, c22, c11]\n",
    "                                Con21.append(tmp2)\n",
    "                    \n",
    "                    # Plotting connectivity values\n",
    "                    print(sender, receiver)\n",
    "                    plt.subplot(4, 4, iter)\n",
    "                    plt.plot(np.squeeze(np.nanmean(Con12, axis=0)), '-',\n",
    "                             lw=2, c='red', alpha=0.5)\n",
    "                    if cohppcGC == 3:\n",
    "                        plt.plot(np.squeeze(np.nanmean(Con21, axis=0)),\n",
    "                                 '--', lw=2, c='red', alpha=0.5)\n",
    "                        plt.title(\n",
    "                            f\"__{area_num[sender]}->{area_num[receiver]}\")\n",
    "                    else:\n",
    "                        plt.title(f\"{area_num[sender]},-,{area_num[receiver]}\")\n",
    "\n",
    "                    plt.xticks([], [])\n",
    "                    if iter == 1:\n",
    "                        plt.xlabel('Frequency(Hz)')\n",
    "                        if cohppcGC == 1:\n",
    "                            plt.ylabel('Coherence')\n",
    "                        elif cohppcGC == 2:\n",
    "                            plt.ylabel('PPC')\n",
    "                        elif cohppcGC == 3:\n",
    "                            plt.ylabel('GC')\n",
    "                    if saveFig == 1:\n",
    "                        plt.savefig(f'coh_ppc_gc_{cohppcGC}.png')\n",
    "                        plt.savefig(f'coh_ppc_gc_{cohppcGC}.pdf')\n",
    "\n",
    "# Compile connectivity results into a dictionary and save to a file\n",
    "Con = {'fr': fr,\n",
    "       'Con12': Con12,\n",
    "       'Con21': Con21,\n",
    "       }\n",
    "\n",
    "pickle.dump(Con, open(f\"SavedData/PyCohPpcGC{cohppcGC}.plk\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
